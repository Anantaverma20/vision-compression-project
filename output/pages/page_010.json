{
  "page_number": 10,
  "raw_response": "```json\n{\n  \"page_number\": 10,\n  \"markdown\": \"### 3.5.1. Training DeepEncoder\\n\\nFollowing Vary [36], we utilize a compact language model [15] and use the next token prediction framework to train DeepEncoder. In this stage, we use all OCR 1.0 and 2.0 data aforementioned, as well as 100M general data sampled from the LAION [31] dataset. All data is trained for 2 epochs with a batch size of 1280, using the AdamW [23] optimizer with cosine annealing scheduler [22] and a learning rate of 5e-5. The training sequence length is 4096.\\n\\n### 3.5.2. Training DeepSeek-OCR\\n\\nAfter DeepEncoder is ready, we use data mentioned in Section 3.4 to train the DeepSeek-OCR with the entire training process conducted on the HAI-LLM [14] platform. The entire model uses pipeline parallelism (PP) and is divided into 4 parts, with DeepEncoder taking two parts and the decoder taking two parts. For DeepEncoder, we treat SAM and the compressor as the vision tokenizer, place them in PP0 and freeze their parameters, while treating the CLIP part as input embedding layer and place it in PP1 with unfrozen weights for training. For the language model part, since DeepSeek3B-MoE has 12 layers, we place 6 layers each on PP2 and PP3. We use 20 nodes (each with 8 A100-40G GPUs) for training, with a data parallelism (DP) of 40 and a global batch size of 640. We use the AdamW optimizer with a step-based scheduler and an initial learning rate of 3e-5. For text-only data, the training speed is 90B tokens/day, while for multimodal data, the training speed is 70B tokens/day.\\n\\nTable 2 | We test DeepSeek-OCR's vision-text compression ratio using all English documents with 600-1300 tokens from the Fox [21] benchmarks. Text tokens represent the number of tokens after tokenizing the ground truth text using DeepSeek-OCR's tokenizer. Vision Tokens=64 or 100 respectively represent the number of vision tokens output by DeepEncoder after resizing input images to 512×512 and 640×640.\\n\\n| Text Tokens | Vision Tokens =64 Precision | Vision Tokens =64 Compression | Vision Tokens=100 Precision | Vision Tokens=100 Compression | Pages |\\n| :--- | :---: | :---: | :---: | :---: | :---: |\\n| 600-700 | 96.5% | 10.5× | 98.5% | 6.7× | 7 |\\n| 700-80"
}