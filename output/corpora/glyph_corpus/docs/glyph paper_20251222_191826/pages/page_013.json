{
  "page_number": 13,
  "markdown": "```json\n{\n  \"page_number\": 13,\n  \"markdown\": \"### Table 10: LongBench Benchmark Results (%)\\n\\n| Model | Single-Doc QA (QA Zh) | Single-Doc QA (QA En) | Multi-Doc QA (Mus) | Multi-Doc QA (Dur) | Summarization (News) | Summarization (VcSum) | Few-shot (Sam) | Few-shot (Lsht) | Synthetic (Pa C) |\\n| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\\n| GPT-4.1 | 63.90 | 51.27 | 55.63 | 24.58 | 23.70 | 14.66 | 41.25 | 50.00 | 26.5 |\\n| LLaMA-3.1-8B-Instruct | 62.20 | **54.98** | 31.61 | **33.75** | **24.21** | **16.23** | 7.61 | 0.00 | 7.13 |\\n| Qwen3-8B | 60.98 | 49.78 | 45.54 | 16.69 | 18.55 | 12.08 | 36.47 | 42.00 | 12.81 |\\n| GLM-4-9B-Chat-1M | **63.17** | 52.88 | 39.14 | 28.27 | 23.90 | 16.21 | 36.15 | **47.38** | 2.39 |\\n| Qwen2.5-7B-Instruct-1M | 62.98 | 53.62 | 34.72 | 21.85 | 21.02 | 12.20 | **39.17** | 28.68 | 3.50 |\\n| Glyph | 37.23 | 45.89 | **56.18** | 26.87 | 21.52 | 12.43 | 32.49 | 44.43 | **30.50** |\\n\\n**Table 10:** The rest of the results on LongBench benchmark (%), which encompasses Single-Document QA, Multi-Document QA, Summarization, Few-shot Learning, and Synthetic task.\\n\\n### Efficiency Analysis\\n\\nH100 and measure efficiency along two axes: (i) prefill latency at batch size 1, and (ii) per-sample inference time at the maximum feasible batch size with output length set to 256 tokens. We omit the KV cache testing,",
  "entities": [],
  "summary": ""
}