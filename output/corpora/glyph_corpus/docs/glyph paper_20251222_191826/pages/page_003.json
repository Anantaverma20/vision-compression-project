{
  "page_number": 3,
  "markdown": "```json\n{\n  \"page_number\": 3,\n  \"markdown\": \"## Figure 2\\n\\n**Diagram Content:**\\n\\n*   **Continual Pre-Training:**\\n    *   Input: Instruction (Who saved Little Red Riding Hood?), Context (Text or Image), Response (The Hunter).\\n    *   Process: Long Text Dataset -> Rendering Configs -> Rendering Dataset -> Continual Pre-training -> Glyph-Base.\\n*   **LLM-Driven Rendering Search:**\\n    *   Initial Configuration: Page size, font style, alignment, etc.\\n    *   Cycle: Model inference -> Rendering Data -> Mutate configuration -> LLM Analysis & Critique -> Rank and sample -> Update results -> Evaluation on Validation Set.\\n    *   Output: Optimal Configuration (Best trade-off between compression and performance).\\n*   **Post-Training:**\\n    *   Inputs: SFT Data, OCR Task, RL Data.\\n    *   Process: Glyph-Base -> Policy Model (Supervised Fine-tuning) -> Reference Model -> Glyph.\\n    *   Result: 3-4x Context Extension.\\n\\n**Caption:** Figure 2: Glyph consists of three main stages: continual pre-training on rendered long-text data, LLM-driven genetic search for optimal rendering configurations, and post-training with SFT, RL. Together, these stages enable efficient long-context modeling with visual-text compression.\\n\\n---\\n\\n2024; Peng et al., 2025; Chen et al., 2025a), positional interpolation and extrapolation (Su et al., 2021; Press et al.,",
  "entities": [],
  "summary": ""
}