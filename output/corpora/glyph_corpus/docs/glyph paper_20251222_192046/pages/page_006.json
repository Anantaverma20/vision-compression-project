{
  "page_number": 6,
  "markdown": "```json\n{\n  \"page_number\": 6,\n  \"markdown\": \"## Table 1: Performance comparison of Glyph with leading LLMs on LongBench (%)\\n\\n| Model | Single-Doc QA | | Multi-Doc QA | | Summarization | | Few-shot | | Synthetic | | Code | | Avg |\\n| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\\n| | **QP** | **NQA** | **HQA** | **2QA** | **QSUM** | **GovRep** | **TREC** | **TriQA** | **PR Zh** | **PR En** | **RB** | **LCC** | |\\n| GPT-4.1 | 51.60 | 35.73 | 69.10 | 74.15 | 23.50 | 33.36 | 77.00 | 93.36 | 100.00 | 100.00 | 67.94 | 68.43 | 56.03 |\\n| LLaMA-3.1-8B-Instruct | 44.56 | 26.34 | 56.88 | 46.67 | **23.28** | **32.36** | 19.25 | <u>89.12</u> | 62.20 | <u>99.50</u> | 42.81 | 46.35 | 41.34 |\\n| Qwen2.5-7B-Instruct-1M | **45.29** | 25.61 | 60.70 | 40.51 | <u>22.95</u> | <u>29.97</u> | 59.37 | 86.93 | 98.5 | **100.00** | 29.80 | 21.72 | 42.42 |\\n| Qwen3-8B | <u>44.67</u> | 26.13 | <u>65.83</u> | **73.92** | 19.60 | 26.85 | <u>70.50</u> | 87.98 | **100.00** | 97.26 | 40.89 | 44.8",
  "entities": [],
  "summary": ""
}